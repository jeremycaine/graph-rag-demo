from getpass import getpass
import os

from dotenv import load_dotenv
load_dotenv() 

openai_key = os.getenv("OPENAI_API_KEY")
astra_endpoint = os.getenv("ASTRA_DB_API_ENDPOINT")
astra_token = os.getenv("ASTRA_DB_APPLICATION_TOKEN")

# Verify they loaded (prints first few characters only for security)
print(f"OpenAI Key loaded: {openai_key[:10]}...")
print(f"Astra Endpoint loaded: {astra_endpoint[:30]}...")

from langchain_astradb import AstraDBVectorStore
from langchain_openai import OpenAIEmbeddings

embedding = OpenAIEmbeddings(model="text-embedding-3-large")

vectorstore = AstraDBVectorStore(
    collection_name="simple",
    embedding=embedding,
    api_endpoint=astra_endpoint,
    token=astra_token,
    # Optional: namespace parameter if using a specific keyspace
    # namespace="your_keyspace"
)

print(vectorstore)

import os
import requests

# List of URLs to download
urls = [
    "https://arxiv.org/pdf/2404.16130"
]

# Directory to save the files
save_dir = "./content/sample_data/"

# Ensure the directory exists
os.makedirs(save_dir, exist_ok=True)

# Function to download a file
def download_file(url, save_path):
    response = requests.get(url)
    if response.status_code == 200:
        with open(save_path, 'wb') as file:
            file.write(response.content)
        print(f"Downloaded: {save_path}")
    else:
        print(f"Failed to download: {url}")

# Loop through the URLs and download each file
for url in urls:
    file_name = url.split("/")[-1]
    save_path = os.path.join(save_dir, file_name)
    download_file(url, save_path)

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from unstructured.partition.auto import partition
from langchain_core.documents.base import Document

import os
import glob

# Use glob to find all PDF files in the directory
pdf_files = glob.glob(os.path.join(save_dir, "*"))
docs = []

for pdf_file in pdf_files:
    elements = partition(filename=pdf_file)
    for element in elements:
      metadata = element.metadata.to_dict()
      metadata["element_id"] = element.id
      if "links" in metadata:
        metadata["unstructured_links"] = metadata.pop("links")
      docs.append(Document(
        id=element.id,
        metadata=metadata,
        page_content=element.text,
      ))

vectorstore.add_documents(docs)

print("docs added to vectorstore")

import base64
import zlib
import json

from langchain_community.graph_vectorstores.links import Link, add_links, get_links

batch_number = 0
while True:
    to_extend = vectorstore.metadata_search(filter={"graph_edges": {"$exists": False}}, n=1000)
    
    if len(to_extend) == 0:
        print("\n✓ Processing complete - no more documents to process")
        break
    
    batch_number += 1
    total_docs = len(to_extend)
    print(f"\n{'='*60}")
    print(f"Batch {batch_number}: Processing {total_docs} documents")
    print(f"{'='*60}")

    upgraded_metadata: dict[str, dict] = {}

    for idx, doc in enumerate(to_extend, 1):
        # Show progress every 50 documents
        if idx % 50 == 0 or idx == 1 or idx == total_docs:
            print(f"  Progress: {idx}/{total_docs} ({(idx/total_docs)*100:.1f}%)")
        
        element_ids = set()
        parent_ids = set()

        # Incoming edge from the element ID generated by Unstructured
        element_ids.add(doc.metadata["element_id"])

        if "parent_id" in doc.metadata:
            # Outgoing edge to the parent ID generated by Unstructured
            parent_ids.add(doc.metadata["parent_id"])

        if "metadata" in doc.metadata and "orig_elements" in doc.metadata["metadata"]:
            # Extract Unstructured elements nested in composite elements
            decoded_b64_bytes = base64.b64decode(doc.metadata["metadata"]["orig_elements"])
            elements_json_bytes = zlib.decompress(decoded_b64_bytes)
            elements_json_str = elements_json_bytes.decode("utf-8")
            element_dicts = json.loads(elements_json_str)

            for original_element in element_dicts:
                # Incoming edge from the nested element's ID
                element_ids.add(original_element["element_id"])

                if "parent_id" in original_element["metadata"]:
                    # Outgoing edge to the nested element's parent ID
                    parent_ids.add(original_element["metadata"]["parent_id"])

        # Add all the hierarchical edges extracted by unstructured to the document
        add_links(doc, [Link.bidir(kind="sections", tag=id) for id in element_ids])
        add_links(doc, [Link.bidir(kind="sections", tag=id) for id in parent_ids])

        doc.metadata.update(graph_edges=True)
    
    print(f"✓ Batch {batch_number} complete - processed {total_docs} documents")

print(f"\n{'='*60}")
print("All batches processed successfully!")
print(f"{'='*60}")

# Update the documents to include graph edges
vectorstore.add_documents(to_extend)

print("graph metadata added to vectorstore")

## VISUALISATION??

# gen AI 
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough

llm = ChatOpenAI(temperature=1, model_name="gpt-4-turbo-2024-04-09")

prompt = ChatPromptTemplate.from_template("""
You are an specialist in artificial intelligence. Your role is to answer questions accurately based on the provided context. If the context does not contain enough information, respond by stating that the context doesn't allow you to answer the question.
Here is the context: {context}
Based on the context above, answer this question: {question}""")

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

retriever = vectorstore.as_retriever(
    search_type = "traversal",  # <-- Combines graph traversal with vector retrieval
    search_kwargs = {
        "k": 5,
        "depth": 2,
    },
)

chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
)

resp = chain.invoke(
    "How does Graph RAG work?"
)
print(resp.content)
